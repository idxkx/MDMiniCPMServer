services:
  minicpm-v-server:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: minicpm-v-server:latest
    container_name: minicpm-v-server
    ports:
      - "${HOST_PORT:-8207}:8207"
    environment:
      - PYTHONPATH=/app/src
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8207
      - MODEL_PATH=/app/models
      - CUDA_VISIBLE_DEVICES=0
      # 性能优化环境变量
      - HF_HOME=/app/cache/huggingface
      - TRANSFORMERS_CACHE=/app/cache/huggingface
      - TORCH_HOME=/app/cache/torch
      - TOKENIZERS_PARALLELISM=false
      # PyTorch性能优化
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - CUDA_LAUNCH_BLOCKING=0
    volumes:
      - ../models:/app/models
      - ../.env:/app/.env:ro
      - ~/.cache/huggingface:/app/cache/huggingface:rw
      - cache_volume:/app/cache/torch
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8207/health"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3

volumes:
  cache_volume:
